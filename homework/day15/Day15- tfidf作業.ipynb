{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標：搭建一個TFIDF 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference:https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "documentA = 'the man went out for a walk'\n",
    "documentB = 'the children sat around the fire'\n",
    "documentC = 'children like ice cream'\n",
    "documentD = 'parents need to take care of their children'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先我們做tokenize，並取出所有文件中的單詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize_A ['the', 'man', 'went', 'out', 'for', 'a', 'walk']\n",
      "tokenize_B ['the', 'children', 'sat', 'around', 'the', 'fire']\n",
      "tokenize_C ['children', 'like', 'ice', 'cream']\n",
      "tokenize_D ['parents', 'need', 'to', 'take', 'care', 'of', 'their', 'children']\n",
      "uniqueWords {'around', 'went', 'out', 'sat', 'care', 'the', 'their', 'ice', 'cream', 'like', 'a', 'fire', 'walk', 'of', 'need', 'to', 'parents', 'take', 'children', 'for', 'man'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenize_A = nltk.word_tokenize(documentA)\n",
    "tokenize_B = nltk.word_tokenize(documentB)\n",
    "tokenize_C = nltk.word_tokenize(documentC)\n",
    "tokenize_D = nltk.word_tokenize(documentD)\n",
    "\n",
    "uniqueWords = set(tokenize_A).union(set(tokenize_B)).union(set(tokenize_C)).union(set(tokenize_D)) ##所有文件中的單詞\n",
    "\n",
    "print('tokenize_A', tokenize_A)\n",
    "print('tokenize_B', tokenize_B)\n",
    "print('tokenize_C', tokenize_C)\n",
    "print('tokenize_D', tokenize_D)\n",
    "print('uniqueWords', uniqueWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算每個文件中，所有uniqueWords出現的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numOfWordsA {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 0, 'the': 0, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 0, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 0, 'for': 0, 'man': 0}\n",
      "numOfWordsB {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 0, 'the': 0, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 0, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 0, 'for': 0, 'man': 0}\n",
      "numOfWordsC {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 0, 'the': 0, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 0, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 0, 'for': 0, 'man': 0}\n",
      "numOfWordsD {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 0, 'the': 0, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 0, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 0, 'for': 0, 'man': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 建立 dict for A, 用來儲存單字在 document A 出現的次數\n",
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "\n",
    "print('numOfWordsA', numOfWordsA)\n",
    "for word in tokenize_A:\n",
    "    numOfWordsA[word] += 1\n",
    "\n",
    "    \n",
    "# 建立 dict for B, 用來儲存單字在 document B 出現的次數\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "print('numOfWordsB', numOfWordsB)\n",
    "\n",
    "for word in tokenize_B:\n",
    "    numOfWordsB[word] += 1\n",
    "\n",
    "# 建立 dict for C, 用來儲存單字在 document C 出現的次數\n",
    "numOfWordsC = dict.fromkeys(uniqueWords, 0)\n",
    "print('numOfWordsC', numOfWordsC)\n",
    "\n",
    "for word in tokenize_C:\n",
    "    numOfWordsC[word] += 1\n",
    "\n",
    "# 建立 dict for D, 用來儲存單字在 document D 出現的次數\n",
    "numOfWordsD = dict.fromkeys(uniqueWords, 0)\n",
    "print('numOfWordsD', numOfWordsD)\n",
    "\n",
    "for word in tokenize_D:\n",
    "    numOfWordsD[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義function:計算TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, tokenize_item):\n",
    "    \"\"\"\n",
    "    wordDict : 文件內單詞對應出現數量的字典\n",
    "    tokenize_item : 文件tokenize後的輸出\n",
    "    \"\"\"\n",
    "    print('\\n wordDict', wordDict)\n",
    "    print('\\n tokenize_item', tokenize_item)\n",
    "    \n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(tokenize_item) ## tokenize_item單詞數量\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/bagOfWordsCount ##單詞在該文件出現的次數/該文件擁有的所有單詞數量\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義function:計算IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documentsDict):\n",
    "    \"\"\"\n",
    "    documentsDict:為一個list，包含所有文件的wordDict\n",
    "    \"\"\"\n",
    "    import math # 可以計算 log\n",
    "    \n",
    "    # 文件數量(分母)\n",
    "    N = len(documentsDict)\n",
    "    \n",
    "    # initialize idfDict\n",
    "    idfDict = dict.fromkeys(documentsDict[0].keys(), 0)\n",
    "    print('initialize idfDict', idfDict)\n",
    "    \n",
    "    for document in documentsDict:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1 ## 計算單詞在多少文件中出現過\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        if val == 0:\n",
    "            continue\n",
    "        else:\n",
    "            idfDict[word] = math.log(N / val) ## 計算IDF，Log (所有文件的數目/包含這個單詞的文件數目)\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義function:計算TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tf_item, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_item.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " wordDict {'around': 0, 'went': 1, 'out': 1, 'sat': 0, 'care': 0, 'the': 1, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 1, 'fire': 0, 'walk': 1, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 0, 'for': 1, 'man': 1}\n",
      "\n",
      " tokenize_item ['the', 'man', 'went', 'out', 'for', 'a', 'walk']\n",
      "tfA {'around': 0.0, 'went': 0.14285714285714285, 'out': 0.14285714285714285, 'sat': 0.0, 'care': 0.0, 'the': 0.14285714285714285, 'their': 0.0, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.14285714285714285, 'fire': 0.0, 'walk': 0.14285714285714285, 'of': 0.0, 'need': 0.0, 'to': 0.0, 'parents': 0.0, 'take': 0.0, 'children': 0.0, 'for': 0.14285714285714285, 'man': 0.14285714285714285}\n",
      "\n",
      "\n",
      " wordDict {'around': 1, 'went': 0, 'out': 0, 'sat': 1, 'care': 0, 'the': 2, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 1, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 1, 'for': 0, 'man': 0}\n",
      "\n",
      " tokenize_item ['the', 'children', 'sat', 'around', 'the', 'fire']\n",
      "tfB {'around': 0.16666666666666666, 'went': 0.0, 'out': 0.0, 'sat': 0.16666666666666666, 'care': 0.0, 'the': 0.3333333333333333, 'their': 0.0, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.0, 'fire': 0.16666666666666666, 'walk': 0.0, 'of': 0.0, 'need': 0.0, 'to': 0.0, 'parents': 0.0, 'take': 0.0, 'children': 0.16666666666666666, 'for': 0.0, 'man': 0.0}\n",
      "\n",
      "\n",
      " wordDict {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 0, 'the': 0, 'their': 0, 'ice': 1, 'cream': 1, 'like': 1, 'a': 0, 'fire': 0, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 1, 'for': 0, 'man': 0}\n",
      "\n",
      " tokenize_item ['children', 'like', 'ice', 'cream']\n",
      "tfC {'around': 0.16666666666666666, 'went': 0.0, 'out': 0.0, 'sat': 0.16666666666666666, 'care': 0.0, 'the': 0.3333333333333333, 'their': 0.0, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.0, 'fire': 0.16666666666666666, 'walk': 0.0, 'of': 0.0, 'need': 0.0, 'to': 0.0, 'parents': 0.0, 'take': 0.0, 'children': 0.16666666666666666, 'for': 0.0, 'man': 0.0}\n",
      "\n",
      "\n",
      " wordDict {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 1, 'the': 0, 'their': 1, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 0, 'walk': 0, 'of': 1, 'need': 1, 'to': 1, 'parents': 1, 'take': 1, 'children': 1, 'for': 0, 'man': 0}\n",
      "\n",
      " tokenize_item ['parents', 'need', 'to', 'take', 'care', 'of', 'their', 'children']\n",
      "tfD {'around': 0.0, 'went': 0.0, 'out': 0.0, 'sat': 0.0, 'care': 0.125, 'the': 0.0, 'their': 0.125, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.0, 'fire': 0.0, 'walk': 0.0, 'of': 0.125, 'need': 0.125, 'to': 0.125, 'parents': 0.125, 'take': 0.125, 'children': 0.125, 'for': 0.0, 'man': 0.0}\n",
      "\n",
      "initialize idfDict {'around': 0, 'went': 0, 'out': 0, 'sat': 0, 'care': 0, 'the': 0, 'their': 0, 'ice': 0, 'cream': 0, 'like': 0, 'a': 0, 'fire': 0, 'walk': 0, 'of': 0, 'need': 0, 'to': 0, 'parents': 0, 'take': 0, 'children': 0, 'for': 0, 'man': 0}\n",
      "idfs {'around': 1.3862943611198906, 'went': 1.3862943611198906, 'out': 1.3862943611198906, 'sat': 1.3862943611198906, 'care': 1.3862943611198906, 'the': 0.6931471805599453, 'their': 1.3862943611198906, 'ice': 1.3862943611198906, 'cream': 1.3862943611198906, 'like': 1.3862943611198906, 'a': 1.3862943611198906, 'fire': 1.3862943611198906, 'walk': 1.3862943611198906, 'of': 1.3862943611198906, 'need': 1.3862943611198906, 'to': 1.3862943611198906, 'parents': 1.3862943611198906, 'take': 1.3862943611198906, 'children': 0.28768207245178085, 'for': 1.3862943611198906, 'man': 1.3862943611198906}\n",
      "\n",
      "\n",
      "說明：當一個單詞的 TF * IDF 值越大時，代表這個單詞對整段文章的重要性也越大，我們可以歸納出：\n",
      "\n",
      "不同單詞在同一個文章中獲得的 TFIDF 值可能不相同，值的高低代表了單詞對整段文章的重要性。\n",
      "同一個單詞在不同文章所得到的 TFIDF 值也可能不同。\n",
      "\n",
      "document A: the man went out for a walk\n",
      "tfidfA {'around': 0.0, 'went': 0.19804205158855578, 'out': 0.19804205158855578, 'sat': 0.0, 'care': 0.0, 'the': 0.09902102579427789, 'their': 0.0, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.19804205158855578, 'fire': 0.0, 'walk': 0.19804205158855578, 'of': 0.0, 'need': 0.0, 'to': 0.0, 'parents': 0.0, 'take': 0.0, 'children': 0.0, 'for': 0.19804205158855578, 'man': 0.19804205158855578}\n",
      "\n",
      "document B: the children sat around the fire\n",
      "tfidfB {'around': 0.23104906018664842, 'went': 0.0, 'out': 0.0, 'sat': 0.23104906018664842, 'care': 0.0, 'the': 0.23104906018664842, 'their': 0.0, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.0, 'fire': 0.23104906018664842, 'walk': 0.0, 'of': 0.0, 'need': 0.0, 'to': 0.0, 'parents': 0.0, 'take': 0.0, 'children': 0.04794701207529681, 'for': 0.0, 'man': 0.0}\n",
      "\n",
      "document C: children like ice cream\n",
      "tfidfC {'around': 0.0, 'went': 0.0, 'out': 0.0, 'sat': 0.0, 'care': 0.0, 'the': 0.0, 'their': 0.0, 'ice': 0.34657359027997264, 'cream': 0.34657359027997264, 'like': 0.34657359027997264, 'a': 0.0, 'fire': 0.0, 'walk': 0.0, 'of': 0.0, 'need': 0.0, 'to': 0.0, 'parents': 0.0, 'take': 0.0, 'children': 0.07192051811294521, 'for': 0.0, 'man': 0.0}\n",
      "\n",
      "document D: parents need to take care of their children\n",
      "tfidfD {'around': 0.0, 'went': 0.0, 'out': 0.0, 'sat': 0.0, 'care': 0.17328679513998632, 'the': 0.0, 'their': 0.17328679513998632, 'ice': 0.0, 'cream': 0.0, 'like': 0.0, 'a': 0.0, 'fire': 0.0, 'walk': 0.0, 'of': 0.17328679513998632, 'need': 0.17328679513998632, 'to': 0.17328679513998632, 'parents': 0.17328679513998632, 'take': 0.17328679513998632, 'children': 0.035960259056472606, 'for': 0.0, 'man': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# comput TF\n",
    "tfA = computeTF(numOfWordsA, tokenize_A)\n",
    "print('tfA {}\\n'.format(tfA))\n",
    "tfB = computeTF(numOfWordsB, tokenize_B)\n",
    "print('tfB {}\\n'.format(tfB))\n",
    "tfC = computeTF(numOfWordsC, tokenize_C)\n",
    "print('tfC {}\\n'.format(tfB))\n",
    "tfD = computeTF(numOfWordsD, tokenize_D)\n",
    "print('tfD {}\\n'.format(tfD))\n",
    "\n",
    "# comput idf => 不同文件的 IDF 值是一樣的\n",
    "idfs = computeIDF([numOfWordsA, numOfWordsB, numOfWordsC, numOfWordsD])\n",
    "print('idfs {}\\n'.format(idfs))\n",
    "\n",
    "# explain tfidf\n",
    "print(\"\"\"\n",
    "說明：當一個單詞的 TF * IDF 值越大時，代表這個單詞對整段文章的重要性也越大，我們可以歸納出：\n",
    "\n",
    "不同單詞在同一個文章中獲得的 TFIDF 值可能不相同，值的高低代表了單詞對整段文章的重要性。\n",
    "同一個單詞在不同文章所得到的 TFIDF 值也可能不同。\n",
    "\"\"\")\n",
    "# comput TFIDF for document A\n",
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "print('document A: {}'.format(documentA))\n",
    "print('tfidfA {}\\n'.format(tfidfA))\n",
    "\n",
    "# comput TFIDF for document B\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "print('document B: {}'.format(documentB))\n",
    "print('tfidfB {}\\n'.format(tfidfB))\n",
    "\n",
    "# comput TFIDF for document C\n",
    "tfidfC = computeTFIDF(tfC, idfs)\n",
    "print('document C: {}'.format(documentC))\n",
    "print('tfidfC {}\\n'.format(tfidfC))\n",
    "\n",
    "# comput TFIDF for document B\n",
    "tfidfD = computeTFIDF(tfD, idfs)\n",
    "print('document D: {}'.format(documentD))\n",
    "print('tfidfD {}\\n'.format(tfidfD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>went</th>\n",
       "      <th>out</th>\n",
       "      <th>sat</th>\n",
       "      <th>care</th>\n",
       "      <th>the</th>\n",
       "      <th>their</th>\n",
       "      <th>ice</th>\n",
       "      <th>cream</th>\n",
       "      <th>like</th>\n",
       "      <th>...</th>\n",
       "      <th>fire</th>\n",
       "      <th>walk</th>\n",
       "      <th>of</th>\n",
       "      <th>need</th>\n",
       "      <th>to</th>\n",
       "      <th>parents</th>\n",
       "      <th>take</th>\n",
       "      <th>children</th>\n",
       "      <th>for</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198042</td>\n",
       "      <td>0.198042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198042</td>\n",
       "      <td>0.198042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>0.346574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     around      went       out       sat      care       the     their  \\\n",
       "0  0.000000  0.198042  0.198042  0.000000  0.000000  0.099021  0.000000   \n",
       "1  0.231049  0.000000  0.000000  0.231049  0.000000  0.231049  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.173287  0.000000  0.173287   \n",
       "\n",
       "        ice     cream      like  ...      fire      walk        of      need  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.198042  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  ...  0.231049  0.000000  0.000000  0.000000   \n",
       "2  0.346574  0.346574  0.346574  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.173287  0.173287   \n",
       "\n",
       "         to   parents      take  children       for       man  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.198042  0.198042  \n",
       "1  0.000000  0.000000  0.000000  0.047947  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.071921  0.000000  0.000000  \n",
       "3  0.173287  0.173287  0.173287  0.035960  0.000000  0.000000  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_all = [tfidfA, tfidfB, tfidfC, tfidfD]\n",
    "\n",
    "df = pd.DataFrame(tfidf_all)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
